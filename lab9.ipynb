{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Laboratorio 9 - Deep Learning\n",
    "\n",
    "### Autores\n",
    "\n",
    "- Angel Higueros 20460\n",
    "- Fredy Velasquez 201011"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1 - Práctica"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Preparación de datos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Importa las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Carga los datos CSV en DataFrames de pandas\n",
    "train_df = pd.read_csv('demand-forecasting-kernels-only/train.csv')\n",
    "test_df = pd.read_csv('demand-forecasting-kernels-only/test.csv')\n",
    "sample_submission_df = pd.read_csv('demand-forecasting-kernels-only/sample_submission.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Muestra las columnas de cada DataFrame\n",
    "print(\"Columnas en train_df:\")\n",
    "print(train_df.columns)\n",
    "\n",
    "print(\"\\nColumnas en test_df:\")\n",
    "print(test_df.columns)\n",
    "\n",
    "print(\"\\nColumnas en sample_submission_df:\")\n",
    "print(sample_submission_df.columns)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Columnas en train_df:\n",
      "Index(['date', 'store', 'item', 'sales'], dtype='object')\n",
      "\n",
      "Columnas en test_df:\n",
      "Index(['id', 'date', 'store', 'item'], dtype='object')\n",
      "\n",
      "Columnas en sample_submission_df:\n",
      "Index(['id', 'sales'], dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Selecciona las columnas relevantes para la normalización en 'train_df'\n",
    "columnas_numericas = ['sales']\n",
    "\n",
    "# Crea un objeto StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajusta el escalador en los datos de entrenamiento y transforma los datos\n",
    "train_df[columnas_numericas] = scaler.fit_transform(train_df[columnas_numericas])\n",
    "\n",
    "# Verifica los datos transformados en 'train_df'\n",
    "print(\"Datos de entrenamiento normalizados:\")\n",
    "print(train_df.head())\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Datos de entrenamiento normalizados:\n",
      "         date  store  item     sales\n",
      "0  2013-01-01      1     1 -1.362804\n",
      "1  2013-01-02      1     1 -1.432246\n",
      "2  2013-01-03      1     1 -1.328083\n",
      "3  2013-01-04      1     1 -1.362804\n",
      "4  2013-01-05      1     1 -1.466966\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Preprocesamiento de Datos\n",
    "\n",
    "# División de series temporales\n",
    "\n",
    "# Supongamos que tienes una columna de fecha llamada \"date\" en tus datos.\n",
    "# Ordena los datos por fecha para asegurarte de que los más recientes estén en el conjunto de prueba.\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "train_df.sort_values(by='date', inplace=True)\n",
    "\n",
    "# Define la fecha de corte para separar los datos en entrenamiento, validación y prueba.\n",
    "fecha_corte_validacion = '2022-07-01'\n",
    "fecha_corte_prueba = '2022-10-01'\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "train_set = train_df[train_df['date'] < fecha_corte_validacion]\n",
    "\n",
    "# Conjunto de validación\n",
    "validation_set = train_df[(train_df['date'] >= fecha_corte_validacion) & (train_df['date'] < fecha_corte_prueba)]\n",
    "\n",
    "# Conjunto de prueba\n",
    "test_set = train_df[train_df['date'] >= fecha_corte_prueba]\n",
    "\n",
    "# Generación de secuencias\n",
    "\n",
    "# Define la ventana de tiempo histórico que deseas utilizar para predecir los próximos 3 meses.\n",
    "ventana_historica = 90  # Por ejemplo, utiliza los últimos 90 días para predecir 3 meses.\n",
    "\n",
    "def crear_secuencias(df, ventana_historica):\n",
    "    secuencias = []\n",
    "    objetivos = []\n",
    "    for i in range(len(df) - ventana_historica):\n",
    "        secuencia = df['sales'].values[i:i+ventana_historica]\n",
    "        objetivo = df['sales'].values[i+ventana_historica:i+ventana_historica+90]  # Pronóstico de 3 meses\n",
    "        secuencias.append(secuencia)\n",
    "        objetivos.append(objetivo)\n",
    "    return np.array(secuencias), np.array(objetivos)\n",
    "\n",
    "# Crea secuencias para los conjuntos de entrenamiento, validación y prueba\n",
    "x_train, y_train = crear_secuencias(train_set, ventana_historica)\n",
    "x_validation, y_validation = crear_secuencias(validation_set, ventana_historica)\n",
    "x_test, y_test = crear_secuencias(test_set, ventana_historica)\n",
    "\n",
    "# Verifica las dimensiones de los conjuntos de datos\n",
    "print(\"Dimensiones de x_train:\", x_train.shape)\n",
    "print(\"Dimensiones de y_train:\", y_train.shape)\n",
    "print(\"Dimensiones de x_validation:\", x_validation.shape)\n",
    "print(\"Dimensiones de y_validation:\", y_validation.shape)\n",
    "print(\"Dimensiones de x_test:\", x_test.shape)\n",
    "print(\"Dimensiones de y_test:\", y_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2 - Teoria "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. ¿Cuál es el problema del gradiente de fuga en las redes LSTM y cómo afecta la efectividad de LSTM para el pronóstico de series temporales?\n",
    "\n",
    "El problema del gradiente de fuga en las redes LSTM se refiere a la tendencia de los gradientes durante la retropropagación a volverse muy pequeños o muy grandes a medida que se propagan hacia atrás en el tiempo a través de muchas unidades de tiempo en una secuencia larga. Esto puede dificultar el entrenamiento efectivo de modelos LSTM para series temporales, ya que los gradientes pequeños pueden llevar a un entrenamiento lento o a un estancamiento, mientras que los gradientes grandes pueden provocar explosiones del gradiente. Esto afecta la efectividad de LSTM para pronósticos de series temporales, ya que puede dificultar la captura de relaciones a largo plazo en los datos.\n",
    "\n",
    "2. ¿Cómo se aborda la estacionalidad en los datos de series temporales cuando se utilizan LSTM para realizar pronósticos y qué papel juega la diferenciación en el proceso?\n",
    "\n",
    "La estacionalidad en los datos de series temporales se aborda en LSTM mediante la diferenciación. La diferenciación implica calcular la diferencia entre valores sucesivos en la serie temporal para eliminar la tendencia y la estacionalidad. Esto convierte la serie en una serie estacionaria que es más fácil de modelar. La diferenciación ayuda a que LSTM capture mejor los patrones temporales en los datos y mejore la precisión de los pronósticos.\n",
    "\n",
    "3. ¿Cuál es el concepto de \"tamaño de ventana\" en el pronóstico de series temporales con LSTM y cómo afecta la elección del tamaño de ventana a la capacidad del modelo para capturar patrones a corto y largo plazo?\n",
    "\n",
    "El \"tamaño de ventana\" en el pronóstico de series temporales con LSTM se refiere a la cantidad de pasos de tiempo anteriores que se utilizan como entrada para predecir el siguiente paso de tiempo. Un tamaño de ventana más grande permite al modelo capturar patrones a largo plazo en los datos, pero también puede hacer que el modelo sea menos sensible a patrones a corto plazo. Por otro lado, un tamaño de ventana más pequeño se centra en patrones a corto plazo, pero puede perder patrones a largo plazo. La elección del tamaño de ventana depende de la naturaleza de los datos y del equilibrio deseado entre la captura de patrones a corto y largo plazo."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.10.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.9 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "d25cdb5aa61f08ef17d60ae5a05baad298235cb381824c57cbe25a28ddd03979"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}